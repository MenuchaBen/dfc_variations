In order to optimize the performance of the DFC algorithm/code, several potential features should be considered:

Evaluation of Transactional Memory Performance
To ensure efficient and reliable performance of the DFC algorithm when using persistent memory, it is important to investigate the potential impact of transactional memory usage. Therefore, an analysis should be conducted to assess whether the use of transactional memory will result in a slowdown and if it is necessary to optimize access to persistent memory for better performance.

Optimization of Access to Persistent Memory
The algorithm was originally designed with the assumption that the most time-consuming functions were the flush calls. However, the write call may save to the actual pmem before the flush is called. This means that write operations may be much slower than initially anticipated. Similarly, read operations can be as slow as write/flush operations, as the code needs to fetch the data from pmem to perform the operation.
We should try and treat pmem memory like we treat file access in order to write faster and more efficient code. To accomplish this, we should read pmem in bulk and work on a locally cached copy until we need to make it persistent, and only then write and flush it. By doing so, we can avoid unnecessary access to the slower memory.


Bulk Read/Write Operations
Since persistent memory can be accessed in large granularity at the same speed, it is recommended to perform bulk read/write operations instead of accessing smaller units of data.

Synchronization with Combiner
To improve the synchronization process with the combiner, the threads that use pop can be made to wait while the others can continue their logic. This optimization can increase the critical section time of the combiner in relation to the fixed overhead of the synchronization and free some of the threads to give even more data for us to procsses, resulting in more efficient performance.
